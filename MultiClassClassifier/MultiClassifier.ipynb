{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.layers import Convolution2D as Conv2D \n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.DatasetV2"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainimages,trainlabels),(testimages,testlabels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOne Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALISING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainbatch = trainimages.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "testbatch = testimages.reshape((10000, 28, 28, 1)).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "valbatch = trainbatch.take(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels=to_categorical(trainlabels)\n",
    "testlabels=to_categorical(testlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_67 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPooli  (None, 12, 12, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPooli  (None, 1, 1, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74602 (291.41 KB)\n",
      "Trainable params: 74602 (291.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv2D(32,3,activation='relu',input_shape =(28,28,1)))\n",
    "\n",
    "Model.add(Conv2D(32, 3, activation='relu', kernel_initializer='he_uniform'))\n",
    "Model.add(MaxPooling2D())\n",
    "\n",
    "Model.add(Conv2D(64, 3, activation='relu', kernel_initializer='he_uniform'))\n",
    "Model.add(MaxPooling2D())\n",
    "\n",
    "Model.add(Conv2D(64, 3, activation='relu', kernel_initializer='he_uniform'))\n",
    "Model.add(MaxPooling2D())\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "Model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "Model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(Model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002EA4D453E20> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002EA4D453E20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002EA4D453E20> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002EA4D453E20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.7719WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002EA4D515B20> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x000002EA4D515B20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002EA4D515B20> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x000002EA4D515B20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "750/750 [==============================] - 33s 43ms/step - loss: 0.6167 - accuracy: 0.7719 - val_loss: 0.4631 - val_accuracy: 0.8292\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.3981 - accuracy: 0.8522 - val_loss: 0.3980 - val_accuracy: 0.8541\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 32s 43ms/step - loss: 0.3268 - accuracy: 0.8784 - val_loss: 0.3157 - val_accuracy: 0.8849\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.2841 - accuracy: 0.8947 - val_loss: 0.3023 - val_accuracy: 0.8902\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.2569 - accuracy: 0.9055 - val_loss: 0.2872 - val_accuracy: 0.8950\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.2322 - accuracy: 0.9148 - val_loss: 0.2721 - val_accuracy: 0.9003\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 32s 43ms/step - loss: 0.2133 - accuracy: 0.9205 - val_loss: 0.2812 - val_accuracy: 0.8988\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.1980 - accuracy: 0.9264 - val_loss: 0.2709 - val_accuracy: 0.8982\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 34s 45ms/step - loss: 0.1838 - accuracy: 0.9327 - val_loss: 0.2677 - val_accuracy: 0.9053\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.1693 - accuracy: 0.9384 - val_loss: 0.2884 - val_accuracy: 0.9029\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 33s 45ms/step - loss: 0.1561 - accuracy: 0.9426 - val_loss: 0.3020 - val_accuracy: 0.9045\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 32s 43ms/step - loss: 0.1458 - accuracy: 0.9462 - val_loss: 0.3558 - val_accuracy: 0.8963\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 33s 43ms/step - loss: 0.1334 - accuracy: 0.9510 - val_loss: 0.3176 - val_accuracy: 0.9058\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 33s 45ms/step - loss: 0.1256 - accuracy: 0.9540 - val_loss: 0.3470 - val_accuracy: 0.9032\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.1158 - accuracy: 0.9570 - val_loss: 0.3605 - val_accuracy: 0.9040\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 30s 40ms/step - loss: 0.1089 - accuracy: 0.9605 - val_loss: 0.3206 - val_accuracy: 0.9029\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 30s 40ms/step - loss: 0.1003 - accuracy: 0.9632 - val_loss: 0.3456 - val_accuracy: 0.9007\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 30s 40ms/step - loss: 0.0953 - accuracy: 0.9643 - val_loss: 0.3837 - val_accuracy: 0.8972\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 29s 39ms/step - loss: 0.0892 - accuracy: 0.9675 - val_loss: 0.3699 - val_accuracy: 0.9014\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 29s 39ms/step - loss: 0.0844 - accuracy: 0.9695 - val_loss: 0.4363 - val_accuracy: 0.8964\n"
     ]
    }
   ],
   "source": [
    "history = Model.fit(trainbatch,trainlabels,epochs=20,batch_size=64, validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
